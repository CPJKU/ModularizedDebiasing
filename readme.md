# Diff-Pruning with Adverserial Training

This code implements various models related to adverserial training and diff-pruning (Guo et. al., 2020)

## Installation

To run the code make sure conda is installed and then run

```bash
conda env create -f environment.yml
```

Then activate the environment by running

```bash
conda activate diff_pruning
```

## Architecture

The project structure looks as follows

ðŸ“¦debiasing_text_classification \
 â”£ ðŸ“‚src \
 â”ƒ â”£ ðŸ“‚models (directory which contains all model classes)\
 â”ƒ â”ƒ â”£ ðŸ“œmodel_adv.py (baseline model for adverserial training) \
 â”ƒ â”ƒ â”£ ðŸ“œmodel_base.py (contains base classes with methods that are used by all models) \
 â”ƒ â”ƒ â”£ ðŸ“œmodel_diff_adv.py (model with 2 subnetworks for adverserial training) \
 â”ƒ â”ƒ â”£ ðŸ“œmodel_diff_task.py (model with subnetwork for task training) \
 â”ƒ â”ƒ â”£ ðŸ“œmodel_heads.py (classifier and adverserial head classes) \
 â”ƒ â”ƒ â”£ ðŸ“œmodel_task.py (baseline model for task training) \
 â”ƒ â”ƒ â”— ðŸ“œweight_parametrizations.py (contains weight parametrizations for subnetwork training*) \
 â”ƒ â”£ ðŸ“œadv_attack.py (contains function to run adverserial attack) \
 â”ƒ â”£ ðŸ“œdata_handler.py \
 â”ƒ â”£ ðŸ“œmetrics.py \
 â”ƒ â”£ ðŸ“œtraining_logger.py \
 â”ƒ â”— ðŸ“œutils.py \
 â”£ ðŸ“œAdvBERT_script.py (testing script for training to verify modular code is working)\
 â”£ ðŸ“œAdvBERT_script2.py (second testing script for training which contains old model classes from main branch)\
 â”£ ðŸ“œcfg.yml (hyperparameters)\
 â”£ ðŸ“œenvironment.yml (conda environment config)\
 â”£ ðŸ“œmain.py (main file to run experiments with)\
 â”£ ðŸ“œmain_attack.py (used to run an adverserial attack only using a model checkpoint)\
 â”— ðŸ“œreadme.md

\* Weight parametrizations are implemented as modules and use pytorch parametrizations functionality [LINK](https://pytorch.org/tutorials/intermediate/parametrizations.html)

## cfg.yml

contains hyperparameter configuration

* data_config \
filepaths to data files
* model_config \
name of pretrained model and batch_size to use
* train_config_diff_pruning \
hyperparameters for diff-pruning-models (model_diff_adv.py and model_diff_task.py)
* train_config_baseline \
hyperparameters for baseline models (model_adv.py and model_task.py)
* adv_attack
hyperparameters for adverserial attack

## Usage

```bash
python3 main.py
```

Optional arguments with example inputs

* --baseline=True \
Run baseline or diff-pruning
* --adv=True \
Run adverserial training
* --gpu_id 0 1 2 3 \
Which gpus to run experiment on (can be multiple)
* --debug=True \
To verify code can run through, limits number of batches which are used to 10
* --run_adv_attack=False \
Set to false if you do not want to run adverserial attack after training