{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tensorboard(path, scalars = None):\n",
    "    \"\"\"returns a dictionary of pandas dataframes for each requested scalar\"\"\"\n",
    "    ea = event_accumulator.EventAccumulator(\n",
    "        path,\n",
    "        size_guidance={event_accumulator.SCALARS: 0},\n",
    "    )\n",
    "    _absorb_print = ea.Reload()\n",
    "    # make sure the scalars are in the event accumulator tags\n",
    "    # assert all(\n",
    "    #     s in ea.Tags()[\"scalars\"] for s in scalars\n",
    "    # ), \"some scalars were not found in the event accumulator\"\n",
    "    res = {}\n",
    "    if scalars is None:\n",
    "        scalars = ea.Tags()[\"scalars\"]\n",
    "    for s in scalars:\n",
    "        try:\n",
    "            res[s] = pd.DataFrame(ea.Scalars(s))\n",
    "        except:\n",
    "            continue\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scalar_stats(\n",
    "    exp_results,\n",
    "    strategy = \"max\", # max, min, last, argmin, argmax\n",
    "    idx_results = None,\n",
    "    return_stats = True\n",
    "):\n",
    "\n",
    "    if strategy == \"argmin\" or strategy == \"argmax\":\n",
    "        \n",
    "        assert idx_results is not None\n",
    "        get_fn_idx = lambda x: (x.argmax() if strategy == \"argmax\" else x.argmin())\n",
    "        idx_list = [get_fn_idx(x[\"value\"]) for x in idx_results]\n",
    "        res = np.array([x[\"value\"].iloc[i] for i, x in zip(idx_list, exp_results)])\n",
    "\n",
    "    else:\n",
    "\n",
    "        if strategy == \"max\":\n",
    "            get_fn = lambda x: x.max()\n",
    "        elif strategy == \"min\":\n",
    "            get_fn = lambda x: x.max()\n",
    "        elif strategy == \"last\":\n",
    "            get_fn = lambda x: x.iloc[-1]\n",
    "        else:\n",
    "            raise Exception(f\"strategy {strategy} undefined\")\n",
    "        res = np.array([get_fn(x[\"value\"]) for x in exp_results])\n",
    "\n",
    "    if return_stats:\n",
    "        return np.array([res.mean(), res.std()])\n",
    "    else:\n",
    "        return res\n",
    "\n",
    "\n",
    "def get_scalar_stats_wrapper_max(results, exp_name, scalar):\n",
    "    exp_results = results[exp_name][scalar]\n",
    "    return get_scalar_stats(exp_results, strategy=\"max\")   \n",
    "\n",
    "def get_scalar_stats_wrapper_last(results, exp_name, scalar):\n",
    "    exp_results = results[exp_name][scalar]\n",
    "    return get_scalar_stats(exp_results, strategy=\"last\")\n",
    "\n",
    "def get_scalar_stats_wrapper_last_approx(results, exp_name, scalar):\n",
    "    matches = [s for s in results[exp_name].keys() if scalar in s]\n",
    "    exp_results = results[exp_name][matches[0]]\n",
    "    return get_scalar_stats(exp_results, strategy=\"last\") \n",
    "\n",
    "def get_scalar_stats_wrapper_argmin(results, exp_name, scalar, scalar_idx):\n",
    "    exp_results = results[exp_name][scalar]\n",
    "    idx_results = results[exp_name][scalar_idx]\n",
    "    return get_scalar_stats(exp_results, strategy=\"argmin\", idx_results=idx_results)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalars = [\n",
    "    \"val/acc_task\",\n",
    "    \"val/loss_task\",\n",
    "    \"val/balanced_acc_adv_attack\",\n",
    "    \"val/loss_adv_attack\",\n",
    "    \"zero_ratio\"\n",
    "]\n",
    "# scalars = [\n",
    "#     'val/acc_task_eval',\n",
    "#     'val/loss_task_eval',\n",
    "#     'val/balanced_acc_adv_attack_gender',\n",
    "#     'val/loss_adv_attack_gender',\n",
    "#     'val/balanced_acc_adv_attack_age',\n",
    "#     'val/loss_adv_attack_age'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert_uncased_L-4_H-256_A-4\" # \"bert-base-uncased\" # \"bert-base-uncased\"  # \"bert_uncased_L-4_H-256_A-4\"\n",
    "folder = \"/home/deepak/sparse_transformers/logs_hatespeech\"\n",
    "experiment_names = set([re.sub(r\"(?<=seed)[\\d]+\", \"{}\", n) for n in os.listdir(folder)]) # remove seed suffix\n",
    "results = {}\n",
    "for f in os.listdir(folder):\n",
    "    exp_name = re.sub(r\"(?<=seed)[\\d]+\", \"{}\", f)\n",
    "    filepath = os.path.join(folder, f)\n",
    "    df = parse_tensorboard(filepath)\n",
    "    try:\n",
    "        results[exp_name].append(df)\n",
    "    except KeyError:\n",
    "        results[exp_name] = [df]\n",
    "\n",
    "results = {k.replace(\"-\" + model_name, \"\").replace(\"-seed{}\", \"\"):v for k,v in results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"results.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"results.pkl\", \"rb\") as f:\n",
    "#     results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_prep = {}\n",
    "for exp, data in results.items():\n",
    "    results_prep[exp] = {}\n",
    "    for res_seed in data:\n",
    "        for k, v in res_seed.items():\n",
    "            for s in scalars:\n",
    "                if s in k:\n",
    "                    try:\n",
    "                        results_prep[exp][k].append(v)\n",
    "                    except:\n",
    "                        results_prep[exp][k] = [v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adverserial-baseline-64-2e-05-weighted_loss_prot-dialect\n",
      "adverserial-Adp-64-2e-05-weighted_loss_prot-dialect\n",
      "adverserial-Adp_fusion-64-2e-05-weighted_loss_prot-dialect\n",
      "adverserial-Adp_prot-64-2e-05-weighted_loss_prot-dialect\n",
      "task-Adp-64-2e-05\n",
      "task-baseline-64-2e-05\n"
     ]
    }
   ],
   "source": [
    "for s in results_prep.keys():\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove cp_init\n",
    "results_prep = {k.replace(\"only_adv_attack_\", \"\"):v for k,v in results_prep.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove cp_init\n",
    "# results_prep = {k.replace(\"-cp_init\", \"\").replace(\"-freeze_task_head_cp\", \"\"):v for k,v in results_prep.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop no_cooldown experiments\n",
    "# results_prep = {k:v for k,v in results_prep.items() if \"no_cooldown\" not in k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort values\n",
    "results_prep = {k:results_prep[k] for k in sorted(results_prep.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adv_0.05_additive_seed{}', 'mod_0.05_additive_seed{}']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(results_prep.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val/acc_task_eval',\n",
       " 'val/balanced_acc_adv_attack_age',\n",
       " 'val/balanced_acc_adv_attack_gender',\n",
       " 'val/loss_adv_attack_age',\n",
       " 'val/loss_adv_attack_gender',\n",
       " 'val/loss_task_eval'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([k for d in results_prep.values() for k in d.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_keys = {\n",
    "    \"pan16\": [\"gender\", \"age\", \"all\"],\n",
    "    \"bios\": [\"gender\", \"all\"],\n",
    "    \"hatespeech\": [\"dialect\", \"all\"]\n",
    "}\n",
    "\n",
    "key_map = {\n",
    "    'task-baseline': [\n",
    "        'val/acc_task',\n",
    "        ['val/balanced_acc_adv_attack_task_emb_target_key_{}', 'val/loss_adv_attack_task_emb_target_key_{}']\n",
    "    ],\n",
    "    'task-diff_pruning': [\n",
    "        'val/acc_task',\n",
    "        ['val/balanced_acc_adv_attack_task_emb_target_key_{}', 'val/loss_adv_attack_task_emb_target_key_{}'],\n",
    "        'train/zero_ratio_adv'\n",
    "    ],\n",
    "    'adverserial-baseline': [\n",
    "        'val/acc_task_debiased',\n",
    "        ['val/balanced_acc_adv_attack_task_emb_target_key_{}', 'val/loss_adv_attack_task_emb_target_key_{}'],\n",
    "        ['val/balanced_acc_adv_attack_adv_emb_{}_target_key_{}', 'val/loss_adv_attack_adv_emb_{}_target_key_{}'],\n",
    "    ],\n",
    "    'adverserial-diff_pruning': [\n",
    "        'val/acc_task_debiased',\n",
    "        ['val/balanced_acc_adv_attack_task_emb_target_key_{}', 'val/loss_adv_attack_task_emb_target_key_{}'],\n",
    "        ['val/balanced_acc_adv_attack_adv_emb_{}_target_key_{}', 'val/loss_adv_attack_adv_emb_{}_target_key_{}'],\n",
    "        'train/zero_ratio_adv'\n",
    "    ],\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "keys_merged_masks = [\n",
    "    ['val/acc_task_eval', 'val/loss_task_eval'],\n",
    "    ['val/balanced_acc_adv_attack_gender', 'val/loss_adv_attack_gender'],\n",
    "    ['val/balanced_acc_adv_attack_age', 'val/loss_adv_attack_age']\n",
    "]\n",
    "\n",
    "\n",
    "keys_modular_pan16 = [\n",
    "    'val/acc_task',\n",
    "    'val/acc_task_debiased_gender',\n",
    "    'val/acc_task_debiased_age',\n",
    "    ['val/balanced_acc_adv_attack_task_emb_target_key_gender', 'val/loss_adv_attack_task_emb_target_key_gender'],\n",
    "    ['val/balanced_acc_adv_attack_task_emb_target_key_age', 'val/loss_adv_attack_task_emb_target_key_age'],\n",
    "    ['val/balanced_acc_adv_attack_adv_emb_gender_target_key_gender', 'val/loss_adv_attack_adv_emb_gender_target_key_gender'],\n",
    "    ['val/balanced_acc_adv_attack_adv_emb_gender_target_key_age', 'val/loss_adv_attack_adv_emb_gender_target_key_age'],\n",
    "    ['val/balanced_acc_adv_attack_adv_emb_age_target_key_gender', 'val/loss_adv_attack_adv_emb_age_target_key_gender'],\n",
    "    ['val/balanced_acc_adv_attack_adv_emb_age_target_key_age', 'val/loss_adv_attack_adv_emb_age_target_key_age'],\n",
    "    'train/zero_ratio_adv_gender',\n",
    "    'train/zero_ratio_adv_age'\n",
    "]\n",
    "\n",
    "keys_modular_pan16_adv_merged = [\n",
    "    'val/acc_task',\n",
    "    'val/acc_task_debiased',\n",
    "    ['val/balanced_acc_adv_attack_task_emb_target_key_gender', 'val/loss_adv_attack_task_emb_target_key_gender'],\n",
    "    ['val/balanced_acc_adv_attack_task_emb_target_key_age', 'val/loss_adv_attack_task_emb_target_key_age'],\n",
    "    ['val/balanced_acc_adv_attack_adv_emb_all_target_key_gender', 'val/loss_adv_attack_adv_emb_all_target_key_gender'],\n",
    "    ['val/balanced_acc_adv_attack_adv_emb_all_target_key_age', 'val/loss_adv_attack_adv_emb_all_target_key_age'],\n",
    "    'train/zero_ratio_adv',\n",
    "]\n",
    "\n",
    "\n",
    "keys_modular_bios = [\n",
    "    'val/acc_task',\n",
    "    'val/acc_task_debiased_gender',\n",
    "    ['val/balanced_acc_adv_attack_task_emb_target_key_gender', 'val/loss_adv_attack_task_emb_target_key_gender'],\n",
    "    ['val/balanced_acc_adv_attack_adv_emb_gender_target_key_gender', 'val/loss_adv_attack_adv_emb_gender_target_key_gender'],\n",
    "    'train/zero_ratio_adv_gender'\n",
    "]\n",
    "\n",
    "\n",
    "keys_modular_hatespeech = [\n",
    "    'val/acc_task',\n",
    "    'val/acc_task_debiased_dialect',\n",
    "    ['val/balanced_acc_adv_attack_task_emb_target_key_dialect', 'val/loss_adv_attack_task_emb_target_key_dialect'],\n",
    "    ['val/balanced_acc_adv_attack_adv_emb_dialect_target_key_dialect', 'val/loss_adv_attack_adv_emb_dialect_target_key_dialect'],\n",
    "    'train/zero_ratio_adv_dialect'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_key_map(ds):\n",
    "    key_map_ = {}\n",
    "    for k,v in key_map.items():\n",
    "        tmp = [v[0]] + [[y.format(x) for y in v[1]] for x in adv_keys[ds]]\n",
    "        if \"adv\" in k:\n",
    "            for a, b in product(adv_keys[ds], adv_keys[ds]):\n",
    "                tmp.append([y.format(a, b) for y in v[2]])\n",
    "        if \"diff\" in k:\n",
    "            tmp.append(v[-1])\n",
    "        key_map_[k] = tmp\n",
    "    return key_map_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adv_0.05_additive_seed{}\n",
      "\n",
      "\n",
      "mod_0.05_additive_seed{}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pan16 standard\n",
    "key_map_pan16 = fill_key_map(\"pan16\")\n",
    "for exp, data in results_prep.items():\n",
    "    print(exp)\n",
    "    for exp_str, keys in key_map_pan16.items():\n",
    "        if exp_str in exp:\n",
    "            for k in keys:\n",
    "                try:\n",
    "                    check = k in data.keys()\n",
    "                    k_name = k\n",
    "                    fn = lambda results_prep, exp: get_scalar_stats_wrapper_last(results_prep, exp, k)\n",
    "                except TypeError:\n",
    "                    check = k[0] in data.keys()\n",
    "                    k_name = k[0]\n",
    "                    fn = lambda results_prep, exp: get_scalar_stats_wrapper_argmin(results_prep, exp, *k)\n",
    "                if check:\n",
    "                    res = fn(results_prep, exp)\n",
    "                    print(f\"{k_name}: {res[0]:.3f} +- {res[1]:.3f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "                #if check:\n",
    "        #         acc_task = get_scalar_stats_wrapper_last(results_prep, exp, keys[0])\n",
    "        # bacc_g = get_scalar_stats_wrapper_argmin(results_prep, exp, *keys[1])\n",
    "        # bacc_a = get_scalar_stats_wrapper_argmin(results_prep, exp, *keys[2])\n",
    "        # print(exp)\n",
    "        # print(f\"acc task: {acc_task[0]:.3f} +- {acc_task[1]:.3f}\")\n",
    "        # print(f\"bacc attack gender: {bacc_g[0]:.3f} +- {bacc_g[1]:.3f}\")\n",
    "        # print(f\"bacc attack age: {bacc_a[0]:.3f} +- {bacc_a[1]:.3f}\")\n",
    "        # if \"diff\" in exp:\n",
    "        #     zero_ratio = get_scalar_stats_wrapper_last_approx(results_prep, exp, \"zero_ratio\")\n",
    "        #     print(f\"zero ratio: {zero_ratio[0]:.3f} +- {zero_ratio[1]:.3f}\")\n",
    "        # print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adverserial-diff_pruning_0.01-64-2e-05-sp_pen1.25e-07-cp_init-weighted_loss_prot-gender\n",
      "val/acc_task_debiased: 0.845 +- 0.001\n",
      "val/balanced_acc_adv_attack_adv_emb_all_target_key_gender: 0.616 +- 0.007\n",
      "train/zero_ratio_adv: 0.990 +- 0.000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# bios and hatespeech\n",
    "km = fill_key_map(\"bios\")\n",
    "for exp, data in results_prep.items():\n",
    "    print(exp)\n",
    "    for exp_str, keys in km.items():\n",
    "        if exp_str in exp:\n",
    "            for k in keys:\n",
    "                try:\n",
    "                    check = k in data.keys()\n",
    "                    k_name = k\n",
    "                    fn = lambda results_prep, exp: get_scalar_stats_wrapper_last(results_prep, exp, k)\n",
    "                except TypeError:\n",
    "                    check = k[0] in data.keys()\n",
    "                    k_name = k[0]\n",
    "                    fn = lambda results_prep, exp: get_scalar_stats_wrapper_argmin(results_prep, exp, *k)\n",
    "                if check:\n",
    "                    res = fn(results_prep, exp)\n",
    "                    print(f\"{k_name}: {res[0]:.3f} +- {res[1]:.3f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modular-diff_pruning_0.01-64-2e-05-sp_pen1.25e-07-weighted_loss_prot-gender\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val/acc_task_debiased_age'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/lukash/sparse_transformers/analysis/analyze_tensorboard.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brk8.cp.jku.at/home/lukash/sparse_transformers/analysis/analyze_tensorboard.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m acc_task \u001b[39m=\u001b[39m get_scalar_stats_wrapper_last(results_prep, exp, km[\u001b[39m0\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brk8.cp.jku.at/home/lukash/sparse_transformers/analysis/analyze_tensorboard.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m acc_task_g \u001b[39m=\u001b[39m get_scalar_stats_wrapper_last(results_prep, exp, km[\u001b[39m1\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Brk8.cp.jku.at/home/lukash/sparse_transformers/analysis/analyze_tensorboard.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m acc_task_a \u001b[39m=\u001b[39m get_scalar_stats_wrapper_last(results_prep, exp, km[\u001b[39m2\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brk8.cp.jku.at/home/lukash/sparse_transformers/analysis/analyze_tensorboard.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m bacc_g_task_emb \u001b[39m=\u001b[39m get_scalar_stats_wrapper_argmin(results_prep, exp, \u001b[39m*\u001b[39mkm[\u001b[39m3\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brk8.cp.jku.at/home/lukash/sparse_transformers/analysis/analyze_tensorboard.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m bacc_a_task_emb \u001b[39m=\u001b[39m get_scalar_stats_wrapper_argmin(results_prep, exp, \u001b[39m*\u001b[39mkm[\u001b[39m4\u001b[39m])\n",
      "\u001b[1;32m/home/lukash/sparse_transformers/analysis/analyze_tensorboard.ipynb Cell 20\u001b[0m in \u001b[0;36mget_scalar_stats_wrapper_last\u001b[0;34m(results, exp_name, scalar)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brk8.cp.jku.at/home/lukash/sparse_transformers/analysis/analyze_tensorboard.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_scalar_stats_wrapper_last\u001b[39m(results, exp_name, scalar):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Brk8.cp.jku.at/home/lukash/sparse_transformers/analysis/analyze_tensorboard.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m     exp_results \u001b[39m=\u001b[39m results[exp_name][scalar]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brk8.cp.jku.at/home/lukash/sparse_transformers/analysis/analyze_tensorboard.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m get_scalar_stats(exp_results, strategy\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlast\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val/acc_task_debiased_age'"
     ]
    }
   ],
   "source": [
    "# pan16 modular\n",
    "for exp in results_prep.keys():\n",
    "    print(exp)\n",
    "\n",
    "    if \"adv_merged\" in exp:\n",
    "        km = keys_modular_pan16_adv_merged\n",
    "        acc_task = get_scalar_stats_wrapper_last(results_prep, exp, km[0])\n",
    "        acc_task_deb = get_scalar_stats_wrapper_last(results_prep, exp, km[1])\n",
    "        bacc_g_task_emb = get_scalar_stats_wrapper_argmin(results_prep, exp, *km[2])\n",
    "        bacc_a_task_emb = get_scalar_stats_wrapper_argmin(results_prep, exp, *km[3])\n",
    "        bacc_g_adv_emb = get_scalar_stats_wrapper_argmin(results_prep, exp, *km[4])\n",
    "        bacc_a_adv_emb = get_scalar_stats_wrapper_argmin(results_prep, exp, *km[5])\n",
    "        zero_ratio = get_scalar_stats_wrapper_last(results_prep, exp, km[6])\n",
    "        print(f\"acc task: {acc_task[0]:.3f} +- {acc_task[1]:.3f}\")\n",
    "        print(f\"acc task debiased: {acc_task_deb[0]:.3f} +- {acc_task_deb[1]:.3f}\")\n",
    "        print(f\"bacc attack gender - task emb: {bacc_g_task_emb[0]:.3f} +- {bacc_g_task_emb[1]:.3f}\")\n",
    "        print(f\"bacc attack age - task emb: {bacc_a_task_emb[0]:.3f} +- {bacc_a_task_emb[1]:.3f}\")\n",
    "        print(f\"bacc attack gender - adv emb: {bacc_g_adv_emb[0]:.3f} +- {bacc_g_adv_emb[1]:.3f}\")\n",
    "        print(f\"bacc attack age - adv emb: {bacc_a_adv_emb[0]:.3f} +- {bacc_a_adv_emb[1]:.3f}\")\n",
    "        print(f\"zero ratio: {zero_ratio[0]:.3f} +- {zero_ratio[1]:.3f}\")\n",
    "    else:\n",
    "        km = keys_modular_pan16\n",
    "        acc_task = get_scalar_stats_wrapper_last(results_prep, exp, km[0])\n",
    "        acc_task_g = get_scalar_stats_wrapper_last(results_prep, exp, km[1])\n",
    "        acc_task_a = get_scalar_stats_wrapper_last(results_prep, exp, km[2])\n",
    "        bacc_g_task_emb = get_scalar_stats_wrapper_argmin(results_prep, exp, *km[3])\n",
    "        bacc_a_task_emb = get_scalar_stats_wrapper_argmin(results_prep, exp, *km[4])\n",
    "        bacc_g_gender_emb = get_scalar_stats_wrapper_argmin(results_prep, exp, *km[5])\n",
    "        bacc_a_gender_emb = get_scalar_stats_wrapper_argmin(results_prep, exp, *km[6])\n",
    "        bacc_g_age_emb = get_scalar_stats_wrapper_argmin(results_prep, exp, *km[7])\n",
    "        bacc_a_age_emb = get_scalar_stats_wrapper_argmin(results_prep, exp, *km[8])\n",
    "        zero_ratio_g = get_scalar_stats_wrapper_last(results_prep, exp, km[9])\n",
    "        zero_ratio_a = get_scalar_stats_wrapper_last(results_prep, exp, km[10])\n",
    "        print(f\"acc task: {acc_task[0]:.3f} +- {acc_task[1]:.3f}\")\n",
    "        print(f\"acc task debiased gender: {acc_task_g[0]:.3f} +- {acc_task_g[1]:.3f}\")\n",
    "        print(f\"acc task debiased age: {acc_task_a[0]:.3f} +- {acc_task_a[1]:.3f}\")\n",
    "        print(f\"bacc attack gender - task emb: {bacc_g_task_emb[0]:.3f} +- {bacc_g_task_emb[1]:.3f}\")\n",
    "        print(f\"bacc attack age - task emb: {bacc_a_task_emb[0]:.3f} +- {bacc_a_task_emb[1]:.3f}\")\n",
    "        print(f\"bacc attack gender - g emb: {bacc_g_gender_emb[0]:.3f} +- {bacc_g_gender_emb[1]:.3f}\")\n",
    "        print(f\"bacc attack age - g emb: {bacc_a_gender_emb[0]:.3f} +- {bacc_a_gender_emb[1]:.3f}\")\n",
    "        print(f\"bacc attack gender - a emb: {bacc_g_age_emb[0]:.3f} +- {bacc_g_age_emb[1]:.3f}\")\n",
    "        print(f\"bacc attack age - a emb: {bacc_a_age_emb[0]:.3f} +- {bacc_a_age_emb[1]:.3f}\")\n",
    "        print(f\"zero ratio - g emb: {zero_ratio_g[0]:.3f} +- {zero_ratio_g[1]:.3f}\")\n",
    "        print(f\"zero ratio - a emb: {zero_ratio_a[0]:.3f} +- {zero_ratio_a[1]:.3f}\")\n",
    "        \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adv_0.05_additive_seed{}\n",
      "acc task: 0.910 +- 0.004\n",
      "bacc attack gender: 0.593 +- 0.006\n",
      "bacc attack age: 0.373 +- 0.012\n",
      "\n",
      "\n",
      "mod_0.05_additive_seed{}\n",
      "acc task: 0.914 +- 0.002\n",
      "bacc attack gender: 0.607 +- 0.010\n",
      "bacc attack age: 0.396 +- 0.016\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pan16 merged masks\n",
    "for exp in results_prep.keys():\n",
    "    acc_task = get_scalar_stats_wrapper_argmin(results_prep, exp, *keys_merged_masks[0])\n",
    "    bacc_gender = get_scalar_stats_wrapper_argmin(results_prep, exp, *keys_merged_masks[1])\n",
    "    bacc_age = get_scalar_stats_wrapper_argmin(results_prep, exp, *keys_merged_masks[2])\n",
    "    print(exp)\n",
    "    print(f\"acc task: {acc_task[0]:.3f} +- {acc_task[1]:.3f}\")\n",
    "    print(f\"bacc attack gender: {bacc_gender[0]:.3f} +- {bacc_gender[1]:.3f}\")\n",
    "    print(f\"bacc attack age: {bacc_age[0]:.3f} +- {bacc_age[1]:.3f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task-baseline': ['val/acc_task',\n",
       "  ['val/balanced_acc_adv_attack_task_emb_target_key_{}',\n",
       "   'val/loss_adv_attack_task_emb_target_key_{}']],\n",
       " 'task-diff_pruning': ['val/acc_task',\n",
       "  ['val/balanced_acc_adv_attack_task_emb_target_key_{}',\n",
       "   'val/loss_adv_attack_task_emb_target_key_{}'],\n",
       "  'train/zero_ratio_adv'],\n",
       " 'adverserial-baseline': ['val/acc_task_debiased',\n",
       "  ['val/balanced_acc_adv_attack_task_emb_target_key_{}',\n",
       "   'val/loss_adv_attack_task_emb_target_key_{}'],\n",
       "  ['val/balanced_acc_adv_attack_adv_emb_{}_target_key_{}',\n",
       "   'val/loss_adv_attack_adv_emb_{}_target_key_{}']],\n",
       " 'adverserial-diff_pruning': ['val/acc_task_debiased',\n",
       "  ['val/balanced_acc_adv_attack_task_emb_target_key_{}',\n",
       "   'val/loss_adv_attack_task_emb_target_key_{}'],\n",
       "  ['val/balanced_acc_adv_attack_adv_emb_{}_target_key_{}',\n",
       "   'val/loss_adv_attack_adv_emb_{}_target_key_{}'],\n",
       "  'train/zero_ratio_adv']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/lukash/sparse_transformers/analysis/analyze_tensorboard.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brk8.cp.jku.at/home/lukash/sparse_transformers/analysis/analyze_tensorboard.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m ds \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhatespeech\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brk8.cp.jku.at/home/lukash/sparse_transformers/analysis/analyze_tensorboard.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m pa \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgender\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m ds\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbios\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mdialect\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Brk8.cp.jku.at/home/lukash/sparse_transformers/analysis/analyze_tensorboard.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m exp, keys \u001b[39min\u001b[39;00m km\u001b[39m.\u001b[39;49mitems():\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brk8.cp.jku.at/home/lukash/sparse_transformers/analysis/analyze_tensorboard.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mif\u001b[39;00m exp \u001b[39min\u001b[39;00m results_prep:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brk8.cp.jku.at/home/lukash/sparse_transformers/analysis/analyze_tensorboard.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m         acc_task \u001b[39m=\u001b[39m get_scalar_stats_wrapper_last(results_prep, exp, keys[\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "# bios or hatespeech\n",
    "ds = \"hatespeech\"\n",
    "pa = \"gender\" if ds==\"bios\" else \"dialect\"\n",
    "for exp, keys in km.items():\n",
    "    if exp in results_prep:\n",
    "        acc_task = get_scalar_stats_wrapper_last(results_prep, exp, keys[0])\n",
    "        acc_d = get_scalar_stats_wrapper_argmin(results_prep, exp, *keys[1])\n",
    "        print(exp)\n",
    "        print(f\"acc task: {acc_task[0]:.3f} +- {acc_task[1]:.3f}\")\n",
    "        print(f\"bacc attack {pa}: {acc_d[0]:.3f} +- {acc_d[1]:.3f}\")\n",
    "        if \"diff\" in exp:\n",
    "            zero_ratio = get_scalar_stats_wrapper_last_approx(results_prep, exp, \"zero_ratio\")\n",
    "            print(f\"zero ratio: {zero_ratio[0]:.3f} +- {zero_ratio[1]:.3f}\")\n",
    "        print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modular-diff_pruning_0.01-64-2e-05-sp_pen1.25e-07-weighted_loss_prot-dialect\n",
      "acc task: 0.814 +- 0.005\n",
      "acc task debiased: 0.812 +- 0.006\n",
      "bacc attack - task emb: 0.872 +- 0.013\n",
      "bacc attack - protected emb: 0.754 +- 0.037\n",
      "zero ratio - protected emb: 0.998 +- 0.000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# bios or hatespeech modular\n",
    "# pan16 modular\n",
    "ds = \"hatespeech\"\n",
    "km = keys_modular_bios if ds==\"bios\" else keys_modular_hatespeech\n",
    "for exp in results_prep.keys():\n",
    "    acc_task = get_scalar_stats_wrapper_last(results_prep, exp, km[0])\n",
    "    acc_task_debiased = get_scalar_stats_wrapper_last(results_prep, exp, km[1])\n",
    "    bacc_prot_task_emb = get_scalar_stats_wrapper_argmin(results_prep, exp, *km[2])\n",
    "    bacc_prot_prot_emb = get_scalar_stats_wrapper_argmin(results_prep, exp, *km[3])\n",
    "    zero_ratio_prot_emb = get_scalar_stats_wrapper_last(results_prep, exp, km[4])\n",
    "    print(exp)\n",
    "    print(f\"acc task: {acc_task[0]:.3f} +- {acc_task[1]:.3f}\")\n",
    "    print(f\"acc task debiased: {acc_task_debiased[0]:.3f} +- {acc_task_debiased[1]:.3f}\")\n",
    "    print(f\"bacc attack - task emb: {bacc_prot_task_emb[0]:.3f} +- {bacc_prot_task_emb[1]:.3f}\")\n",
    "    print(f\"bacc attack - protected emb: {bacc_prot_prot_emb[0]:.3f} +- {bacc_prot_prot_emb[1]:.3f}\")\n",
    "    print(f\"zero ratio - protected emb: {zero_ratio_prot_emb[0]:.3f} +- {zero_ratio_prot_emb[1]:.3f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('testenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44fd53a9831942cc7290b70e18d76362301b009d310fe9edb8a5f7b8f5560d5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
